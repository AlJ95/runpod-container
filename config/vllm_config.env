# vLLM Server Configuration
# This file contains environment variables for the vLLM service

# Model configuration
MODEL_NAME="openai/gpt-oss-20b"
MODEL_PATH=""

# Server settings
HOST="0.0.0.0"
PORT=8000

# GPU memory management
GPU_MEMORY_UTILIZATION=0.5 # 48 GB -> 24 GB
ASYNC_SCHEDULING=true

# Performance settings
TENSOR_PARALLEL_SIZE=1
MAX_MODEL_LEN=2048

# Additional vLLM parameters
DISABLE_LOG_REQUESTS=false
MAX_NUM_SEQS=16