# AI Inference Server Requirements
# Dual Virtual Environment Approach for Dependency Isolation

# =============================================
# vLLM SERVICE (.venv_vllm)
# =============================================
# Core dependencies for vLLM
vllm==0.10.2

# NVIDIA CUDA libraries for vLLM
nvidia-cublas-cu12==12.1.3.1
nvidia-cudnn-cu12==8.9.2.26
nvidia-cuda-nvrtc-cu12==12.1.105
nvidia-cuda-runtime-cu12==12.1.105

# Hugging Face transfer
hf_transfer==0.1.4

# =============================================
# AUDIO & TTS SERVICES (.venv_audio_tts)
# =============================================
# Core dependencies for Whisper
faster-whisper==0.10.0

# API dependencies
fastapi==0.110.0
uvicorn==0.27.0
python-multipart==0.0.6

# VibeVoice TTS dependencies
vector-quantize-pytorch==1.12.0
vocos==0.1.0

# NVIDIA CUDA libraries for Audio/TTS
nvidia-cublas-cu12==12.1.3.1
nvidia-cudnn-cu12==8.9.2.26
nvidia-cuda-nvrtc-cu12==12.1.105
nvidia-cuda-runtime-cu12==12.1.105

# =============================================
# DEVELOPMENT DEPENDENCIES (Optional)
# =============================================
uv==0.1.20

# Type hints and linting
mypy==1.8.0
pylint==3.1.0
black==23.12.1
isort==5.13.2

# =============================================
# INSTALLATION NOTES
# =============================================
# Use scripts/python_setup.sh to create separate virtual environments
# and install dependencies in isolation to avoid conflicts.
# Do NOT install all dependencies in a single environment.
