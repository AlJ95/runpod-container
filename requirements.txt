# Unified Requirements for RunPod Container
# Combined dependencies for vLLM, Whisper, and TTS

# Core AI/ML Frameworks
torch
torchaudio
vllm==0.10.2
bitsandbytes
llmcompressor
flash-attn

# Whisper Service
faster-whisper
# NOTE:
# openai-whisper has a strict dependency on `triton<3`, but vLLM requires Triton 3.x
# via torch==2.8. We therefore install openai-whisper separately with `--no-deps`
# in scripts/setup.sh.
tokenizers

# TTS Service (VibeVoice)
transformers>=4.41.0,<4.56
# CosyVoice upstream pins diffusers==0.29.0; we keep our minimum compatible range.
diffusers>=0.27.0
soundfile
librosa
accelerate

# CosyVoice (minimal runtime deps)
# NOTE: CosyVoice imports `modelscope.snapshot_download` internally (even if we only use HF).
modelscope
hydra-core
omegaconf
HyperPyYAML
inflect
wetext
conformer==0.3.2
x-transformers
pyworld
# Needed by Matcha-TTS utils imported by CosyVoice during YAML instantiation
lightning
gdown
matplotlib
wget

# API & Server
fastapi
uvicorn
python-multipart
runpod

# Tests
pytest
requests

# Utilities & Infrastructure
huggingface-hub
hf_transfer
numpy

# NVIDIA CUDA Libraries (Required for CTranslate2/Whisper in this environment)
nvidia-cublas-cu12
nvidia-cudnn-cu12
nvidia-cuda-nvrtc-cu12
nvidia-cuda-runtime-cu12
